#!/usr/bin/env python
import datapackage
import os
import sys
import codecs
import unicodecsv as csv
from jsontableschema import infer
import glob
import json
from collections import OrderedDict
from colorama import init, Style
from messages import messages, print_message, license_options
init(autoreset=True)


# These are the default values that will be used if no response is given
# None = optional value.
defaults = {
    "description": None,
    "version": "0.1.0",
    "license": "1",  # PDDL
    "homepage": None,
    "keywords": None,
}

# create the DataPackage instance
# ensure we get the output in fixed order by specifying the descriptor argument
dp = datapackage.DataPackage(descriptor=OrderedDict())


def get_response(name, field_name=None, default_value=None):
    '''Presents a prompt and processes the user response for property `name`.'''
    global dp
    if field_name:
        d = field_name
    else:
        d = name
    if name in messages:
        if default_value:
            print_message(name, default_value)
        elif name in defaults:
            print_message(name, defaults[name])
        else:
            print_message(name)
    response = input(messages["question_prompt"])
    if response:
        dp.descriptor[d] = response
    else:
        if default_value:
            dp.descriptor[d] = default_value
        elif name in defaults:
            if defaults[name] is None:
                # optional field
                pass
            else:
                dp.descriptor[d] = defaults[name]
        else:
            # no default value = mandatory field
            print_message("required_field")
            get_response(name, field_name)
    # parse license option
    if name == "license":
        dp.descriptor["license"] = license_options[dp.descriptor["license"]]

# Splash screen :3
print_message('splash')

# Does data/ exist?
if not os.path.exists('data') or not os.path.isdir('data'):
    print_message('error_nodatadir')
    sys.exit()

# Does datapackage.json exist?
if os.path.exists('datapackage.json'):
    print_message('info_exists')

# Ask user for each field
get_response('title')
get_response('slug', field_name='name', default_value=dp.descriptor['title'].lower().replace(' ', '-'))
get_response('description')
get_response('version')
get_response('homepage')
get_response('license')
get_response('keywords')

# Sources
dp.descriptor['sources'] = []
print_message('sources_intro')
another = True
while another:
    source_name = input(Style.BRIGHT + "Source name? ")
    source_url = input(Style.BRIGHT + "Source URL? ")
    s = {}
    dp.descriptor['sources'].append({"name": source_name, "web": source_url})
    print
    add_another = input(Style.BRIGHT + "Add another source? [n] ")
    if add_another not in ("y", "Y"):
        another = False

# Contributors
dp.descriptor['contributors'] = []
print_message('contributors_intro')
another = True
while another:
    contrib_name = input(Style.BRIGHT + "Contributor name? ")
    contrib_email = input(Style.BRIGHT + "Contributor e-mail (optional)? ")
    contrib_url = input(Style.BRIGHT + "Contributor URL (optional)? ")
    c = {}
    if contrib_name:
        c["name"] = contrib_name
    if contrib_email:
        c["email"] = contrib_email
    if contrib_url:
        c["web"] = contrib_url
    if c:
        add_another = input(Style.BRIGHT + "Add another contributor? [n] ")
        if add_another not in ("y", "Y"):
            another = False
    else:
        another = False


# CSV files
dp.descriptor['resources'] = []
csv_files = glob.glob('data/*.csv')
print
if len(csv_files) == 1:
    print("Found a single CSV file in the data/ dir. Easy!")
elif len(csv_files) != 0:
    print("Found %d CSV files in the data/ dir.") % len(csv_files)
else:
    print("No CSV files found! I currently can't handle anything other than CSV. They'll fix me soon!")

for filepath in csv_files:
    print
    print("Let's now look at " + Style.BRIGHT + filepath + Style.RESET_ALL + "...")
    default_slug = filepath.split("/")[-1].split(".")[0]
    slug = input("  Slug for this file? [%s]" % default_slug)
    resource_name = slug or default_slug
    with open(filepath, 'rb') as f:
        headers = [s.decode("utf-8") for s in f.readline().rstrip(b'\n').split(b',')]
        values = csv.reader(f, encoding="utf-8")
        print("  Inferring column types, this might take a bit...")
        schema = infer(headers, values)
        fields = []
        for field in schema['fields']:
            fieldname = field['name']
            field['title'] = input("  Human title for field '%s'? " % fieldname)
            field['description'] = input("  Short description for field '%s'? " % fieldname)
            fields.append(field)

        dp.descriptor['resources'].append(
            {
                'name': resource_name,
                'path': filepath,
                'schema': fields
            }
        )

out = json.dumps(dp.to_dict(), ensure_ascii=False, indent=2)

if not os.path.exists('datapackage.json'):
    outfilename = 'datapackage.json'
else:
    outfilename = 'datapackage-new.json'
with codecs.open(outfilename, 'w', 'utf-8') as f:
    f.write(out)

print_message("done", outfilename)
